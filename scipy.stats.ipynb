{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment No. 3 Part(F)\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The scipy.stats subpackage is a compilation of \n",
    " •\tnumerous random variable objects (densities, cumulative distributions, random sampling, etc.)\n",
    " •\tsome estimation procedures\n",
    " •\tsome statistical tests\n",
    " \n",
    " This module contains a large number of probability distributions as well as a growing library of statistical functions.\n",
    " \n",
    " ## Numpy Versus Scipy(Random Variable & Distribution)\n",
    " \n",
    " In Numpy, numpy.random provides functions for generating random variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.50653096,  0.34596042,  0.68939241])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.beta(5, 5, size=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here’s an example of usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py:397: UserWarning: matplotlib is currently using a non-GUI backend, so cannot show the figure\n",
      "  \"matplotlib is currently using a non-GUI backend, \"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import beta\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "q = beta(5, 5)      # Beta(a, b), with a = b = 5\n",
    "obs = q.rvs(2000)   # 2000 observations\n",
    "grid = np.linspace(0.01, 0.99, 100)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(obs, bins=40, normed=True)\n",
    "ax.plot(grid, q.pdf(grid), 'k-', linewidth=2)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code we created a so-called rv_frozen object, via the call q = beta(5, 5)\n",
    "The “frozen” part of the notation implies that q represents a particular distribution with a particular set of parameters\n",
    "Once we’ve done so, we can then generate random numbers, evaluate the density, etc., all from this fixed distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26656768000000003"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = beta(5, 5)      # Beta(a, b), with a = b = 5\n",
    "q.cdf(0.4)      # Cumulative distribution function\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0901888000000013"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "In [15]: q.pdf(0.4)      # Density function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63391348346427079"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "In [16]: q.ppf(0.8)      # Quantile (inverse cdf) function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "In [17]: q.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribuation Classes:\n",
    "There are two general distribution classes that has been implemented for statistical analysis of Random Variables :\n",
    "(a) Continous Random Variables with 80 RV's.\n",
    "(b) Discrete Random Variables with 10 RV's.\n",
    "\n",
    "All the Statistical function are contained in the scipy.stats with complete listing available at info (stats).\n",
    "\n",
    "# Common Methods :\n",
    "\n",
    "The main public methods for continuous RVs are:\n",
    "•\trvs: Random Variates\n",
    "•\tpdf: Probability Density Function\n",
    "•\tcdf: Cumulative Distribution Function\n",
    "•\tsf: Survival Function (1-CDF)\n",
    "•\tppf: Percent Point Function (Inverse of CDF)\n",
    "•\tisf: Inverse Survival Function (Inverse of SF)\n",
    "•\tstats: Return mean, variance, (Fisher’s) skew, or (Fisher’s) kurtosis\n",
    "•\tmoment: non-central moments of the distribution\n",
    "\n",
    "\n",
    "# Common Examples: \n",
    "\n",
    "Following three commonly used functions in majority of the scientific research are discussed with examples\n",
    "\n",
    "(a) Histogram and probability density function\n",
    "(b) Percentiles\n",
    "(c) Statistical Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram and probability density function\n",
    "\n",
    "Given observations of a random process, their histogram is an estimator of the random process’s PDF (probability\n",
    "density function):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4, -3, -2, -1,  0,  1,  2,  3,  4])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> import numpy as np\n",
    ">>> a = np.random.normal(size=1000)\n",
    ">>> bins = np.arange(-4, 5)\n",
    ">>> bins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.5, -2.5, -1.5, -0.5,  0.5,  1.5,  2.5,  3.5])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> histogram = np.histogram(a, bins=bins, normed=True)[0]\n",
    ">>> bins = 0.5*(bins[1:] + bins[:-1])\n",
    ">>> bins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x900f1aed30>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> from scipy import stats\n",
    ">>> b = stats.norm.pdf(bins) # norm is a distribution\n",
    ">>> plt.plot(bins, histogram)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x900f1aed68>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> plt.plot(bins, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we know that the random process belongs to a given family of random processes, such as normal processes,\n",
    "we can do a maximum-likelihood fit of the observations to estimate the parameters of the underlying distribution.\n",
    "Here we fit a normal process to the observed data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03655603973611387"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> loc, std = stats.norm.fit(a)\n",
    ">>> loc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99442840998252524"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Percentiles\n",
    "\n",
    "\n",
    "The median is the value with half of the observations below, and half above:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.049591346022477688"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> np.median(a)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "It is also called the percentile 50, because 50% of the observation are below it:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.049591346022477688"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> stats.scoreatpercentile(a, 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can calculate the percentile 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3217137727779449"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> stats.scoreatpercentile(a, 90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical tests\n",
    "\n",
    "A statistical test is a decision indicator. For instance, if we have two sets of observations, that we assume are\n",
    "generated from Gaussian processes, we can use a T-test to decide whether the two sets of observations are\n",
    "significantly different:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-3.5004007860478636, pvalue=0.00067636571958768496)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> a = np.random.normal(0, 1, size=100)\n",
    ">>> b = np.random.normal(1, 1, size=10)\n",
    ">>> stats.ttest_ind(a, b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting output is composed of:\n",
    "• The T statistic value: it is a number the sign of which is proportional to the difference between the two\n",
    "random processes and the magnitude is related to the significance of this difference.\n",
    "• the p value: the probability of both processes being identical. If it is close to 1, the two process are almost\n",
    "certainly identical. The closer it is to zero, themore likely it is that the processes have different means.\n",
    "See also:\n",
    "The chapter on statistics introduces much more elaborate tools for statistical testing and statistical data loading\n",
    "and visualization outside of scipy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specific Points for Discrete Distributions\n",
    "•\tDiscrete distribution have mostly the same basic methods as the continuous distributions. However pdf is replaced the probability mass function pmf, no estimation methods, such as fit, are available, and scale is not a valid keyword parameter. The location parameter, keyword loc can still be used to shift the distribution.\n",
    "•\tThe computation of the cdf requires some extra attention. In the case of continuous distribution the cumulative distribution function is in most standard cases strictly monotonic increasing in the bounds (a,b) and has therefore a unique inverse. The cdf of a discrete distribution, however, is a step function, hence the inverse cdf, i.e., the percent point function, requires a different definition:\n",
    "•\tppf(q) = min{x : cdf(x) >= q, x integer}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Issues and Cautionary Remarks\n",
    "\n",
    "The performance of the individual methods, in terms of speed, varies widely by distribution and method. The results of a method are obtained in one of two ways: either by explicit calculation, or by a generic algorithm that is independent of the specific distribution.\n",
    "Explicit calculation, on the one hand, requires that the method is directly specified for the given distribution, either through analytic formulas or through special functions in scipy.special or numpy.random for rvs. These are usually relatively fast calculations.\n",
    "The generic methods, on the other hand, are used if the distribution does not specify any explicit calculation. To define a distribution, only one of pdf or cdf is necessary; all other methods can be derived using numeric integration and root finding. However, these indirect methods can be very slow. As an example, rgh = stats.gausshyper.rvs(0.5, 2, 2, 2, size=100) creates random variables in a very indirect way and takes about 19 seconds for 100 random variables on my computer, while one million random variables from the standard normal or from the t distribution take just above one second.\n",
    "\n",
    "## Remaining Issues\n",
    "\n",
    "The distributions in scipy.stats have recently been corrected and improved and gained a considerable test suite, however a few issues remain:\n",
    "•\tthe distributions have been tested over some range of parameters, however in some corner ranges, a few incorrect results may remain.\n",
    "•\tthe maximum likelihood estimation in fit does not work with default starting parameters for all distributions and the user needs to supply good starting parameters. Also, for some distribution using a maximum likelihood estimator might inherently not be the best choice.\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
